{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI\n",
    "\n",
    "> Execution module for Deep Animator library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import imageio\n",
    "\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.transform import resize\n",
    "from fastscript import call_parse, Param\n",
    "\n",
    "from deep_animator.utils import load_checkpoints, animate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def deep_animate(source: Param('Path to the source image.', str), \n",
    "                 driving: Param('Path to the driving video.', str), \n",
    "                 config: Param('Path to configuration file.', str), \n",
    "                 checkpoint: Param('Path to model.', str),\n",
    "                 device: Param('cpu or gpu accelaration', str) = 'cpu',\n",
    "                 dest: Param('Path to save the generated video.', str) = 'generated_video.mp4', \n",
    "                 relative: Param('Relative.', bool) = True, \n",
    "                 adapt_movement_scale: Param('Adaptive moment scale.', bool) = True):\n",
    "    \n",
    "    source_image = imageio.imread(source)\n",
    "    driving_video = imageio.imread(driving)\n",
    "    \n",
    "    # resize image and video to 256x256\n",
    "    source_image = resize(source_image, (256, 256))[..., :3]\n",
    "    driving_image = resize(source_image, (256, 256))[..., :3]\n",
    "    \n",
    "    generator, kp_detector = load_checkpoints(config_path=config, checkpoint_path=checkpoint)\n",
    "    \n",
    "    predictions = animate(source_image, driving_image, generator, kp_detector, relative=relative, \n",
    "                          adapt_movement_scale=adapt_movement_scale)\n",
    "    \n",
    "    imageio.imsave(dest, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_animator]",
   "language": "python",
   "name": "conda-env-deep_animator-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}